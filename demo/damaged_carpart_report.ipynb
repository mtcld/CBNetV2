{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d2f7694",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.apis import init_detector, inference_detector, show_result_pyplot\n",
    "import mmcv\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from skimage import draw\n",
    "import pandas as pd\n",
    "import copy\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c491738c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fb3c474",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mmdetection/mmdet/core/anchor/builder.py:15: UserWarning: ``build_anchor_generator`` would be deprecated soon, please use ``build_prior_generator`` \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: ../checkpoints/carpart/swa_carpart.pth\n"
     ]
    }
   ],
   "source": [
    "carpart_config = '../checkpoints/carpart/swa_carpart.py'\n",
    "carpart_checkpoint = '../checkpoints/carpart/swa_carpart.pth'\n",
    "carpart_model = init_detector(carpart_config, carpart_checkpoint, device='cuda:2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0303362e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sli_side_turn_light',\n",
       " 'tyre',\n",
       " 'alloy_wheel',\n",
       " 'hli_head_light',\n",
       " 'hood',\n",
       " 'fwi_windshield',\n",
       " 'flp_front_license_plate',\n",
       " 'door',\n",
       " 'mirror',\n",
       " 'handle',\n",
       " 'qpa_quarter_panel',\n",
       " 'fender',\n",
       " 'grille',\n",
       " 'fbu_front_bumper',\n",
       " 'rocker_panel',\n",
       " 'rbu_rear_bumper',\n",
       " 'pillar',\n",
       " 'roof',\n",
       " 'blp_back_license_plate',\n",
       " 'window',\n",
       " 'rwi_rear_windshield',\n",
       " 'tail_gate',\n",
       " 'tli_tail_light',\n",
       " 'fbe_fog_light_bezel',\n",
       " 'fli_fog_light',\n",
       " 'fuel_tank_door',\n",
       " 'lli_low_bumper_tail_light']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = carpart_model.CLASSES\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c409c12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert annotation segmentation to binary mask\n",
    "def draw_binary_mask(seg, img_shape):\n",
    "    seg = np.array(seg).reshape(-1,2)\n",
    "    polygon = np.array(seg)\n",
    "    mask = draw.polygon2mask(img_shape, polygon)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33745c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute iou between ground truth and predicted binary masks\n",
    "def iou(ground_truth_mask, predict_mask):\n",
    "    area1 = np.sum(ground_truth_mask)\n",
    "    area2 = np.sum(predict_mask)\n",
    "#     print(area1, area2)\n",
    "    #intersections\n",
    "    intersection = np.sum(np.multiply(ground_truth_mask, predict_mask))\n",
    "#     print('intersection', intersection)\n",
    "    union = np.sum(np.add(ground_truth_mask,predict_mask)>0) - intersection\n",
    "#     print('intersection', intersection, 'uni',union)\n",
    "    iou = intersection/union\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54cae106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_damage_size(seg, img_shape):\n",
    "    seg = np.array(seg).reshape(-1,2).astype(np.int32)\n",
    "    area = cv2.contourArea(seg)\n",
    "    if area == 0:\n",
    "        area = 1e-5\n",
    "    ratio = area/(img_shape[0]*img_shape[1])\n",
    "    if ratio <= 5.000000000000013e-05: size = 'Small'\n",
    "    elif ratio <= 0.2: size = 'Medium'\n",
    "    else:\n",
    "        ratio = 'Large'\n",
    "    return size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576b42b1",
   "metadata": {},
   "source": [
    "# Old data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8f7e4335",
   "metadata": {},
   "source": [
    "# #Load test, train, valid json file\n",
    "# path1 = \"../data/coco_datasets/datasets/scratch/annotations/test.json\"\n",
    "# test_data = json.load(open(path1))\n",
    "# print(len(test_data['images']))\n",
    "\n",
    "# path2 = '../data/coco_datasets/datasets/scratch/annotations/train.json'\n",
    "# train_data = json.load(open(path2))\n",
    "# print(len(train_data['images']))\n",
    "\n",
    "# path3 = '../data/coco_datasets/datasets/scratch/annotations/valid.json'\n",
    "# valid_data = json.load(open(path3))\n",
    "# print(len(valid_data['images']))\n",
    "\n",
    "# print('total_images: ', len(test_data['images'])+len(train_data['images'])+len(valid_data['images']))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f9f079a6",
   "metadata": {},
   "source": [
    " \n",
    "# # determine intersection of annotation id of three json file\n",
    "# # annotaion id in test data\n",
    "# test_anno_id =[]\n",
    "# for ann in test_data['annotations']:\n",
    "#     test_anno_id.append(ann['id'])\n",
    "\n",
    "# train_anno_id =[]\n",
    "# for ann in train_data['annotations']:\n",
    "#     train_anno_id.append(ann['id'])\n",
    "\n",
    "# valid_anno_id =[]\n",
    "# for ann in valid_data['annotations']:\n",
    "#     valid_anno_id.append(ann['id'])\n",
    "\n",
    "# intersect1 = list(set(test_anno_id).intersection(set(train_anno_id)))\n",
    "# intersect2 = list(set(test_anno_id).intersection(set(valid_anno_id)))\n",
    "\n",
    "# print(intersect1,'\\n', len(intersect2))\n",
    "# print(len(valid_anno_id))\n",
    "\n",
    "# # intersection = test_data['annotations']\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "348e3cbd",
   "metadata": {},
   "source": [
    "# # determine intersection of annotation id of three json file\n",
    "# # annotaion id in test data\n",
    "# test_img_id =[]\n",
    "# for ann in test_data['images']:\n",
    "#     test_img_id.append(ann['id'])\n",
    "\n",
    "# train_img_id =[]\n",
    "# for ann in train_data['images']:\n",
    "#     train_img_id.append(ann['id'])\n",
    "\n",
    "# valid_img_id =[]\n",
    "# for ann in valid_data['images']:\n",
    "#     valid_img_id.append(ann['id'])\n",
    "\n",
    "# intersect1 = list(set(test_img_id).intersection(set(train_img_id)))\n",
    "# intersect2 = list(set(test_img_id).intersection(set(valid_img_id)))\n",
    "\n",
    "# print(intersect1,'\\n', len(intersect2))\n",
    "# # print(len(valid_anno_id))\n",
    "\n",
    "# # intersection = test_data['annotations']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c7486e1",
   "metadata": {},
   "source": [
    "# def merge(js1,js2):\n",
    "#     out = copy.deepcopy(js1)\n",
    "#     img_gasp = max([i['id'] for i in js1['images']]) + 1\n",
    "#     anno_gasp = max([a['id'] for a in js1['annotations']]) + 1\n",
    "    \n",
    "#     for i in js2['images']:\n",
    "#         i['id'] += img_gasp\n",
    "#         out['images'].append(i)\n",
    "    \n",
    "#     for a in js2['annotations']:\n",
    "#         a['image_id'] += img_gasp\n",
    "#         a['id'] += anno_gasp\n",
    "#         out['annotations'].append(a)\n",
    "    \n",
    "#     return out"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6315f279",
   "metadata": {},
   "source": [
    "# print(len(test_data['annotations'])+len(train_data['annotations']))\n",
    "# print(len(test_data['images'])+len(train_data['images']))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d226a76a",
   "metadata": {},
   "source": [
    "# #merge test, train, valid data to test_train_valid_combination.json\n",
    "# merge_test_train = merge(test_data, train_data)\n",
    "\n",
    "# print(len(merge_test_train['annotations']))\n",
    "# print(len(merge_test_train['images']))\n",
    "# total_data = merge(merge_test_train, valid_data)\n",
    "\n",
    "# file_name = 'test_train_valid_combination'\n",
    "# json_path='../data/coco_datasets/datasets/scratch/annotations/'\n",
    "# with open(os.path.join(json_path, file_name+'.json'), 'w') as json_file:\n",
    "#     json.dump(total_data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4b5181f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23708\n"
     ]
    }
   ],
   "source": [
    "imgs_folder = '../data/coco_datasets/datasets/scratch/images/'\n",
    "print(len([entry for entry in os.listdir(imgs_folder) if os.path.isfile(os.path.join(imgs_folder, entry))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "179555c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iou_dict = defaultdict(list)\n",
    "scratches_on_carparts = defaultdict(int)\n",
    "small_scratch = defaultdict(int)\n",
    "medium_scratch = defaultdict(int)\n",
    "large_scratch = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb6d70e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = 'test_train_valid_combination'\n",
    "json_path='../data/coco_datasets/datasets/scratch/annotations/test_train_valid_combination.json'\n",
    "# with open(os.path.join(json_path, file_name+'.json'), 'w') as json_file:\n",
    "#     json.dump(total_data, json_file, indent=4)\n",
    "total_data = json.load(open(json_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c00b123",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imgToAnns dict: mapping an image Id to a list of annotations\n",
    "anns = {}\n",
    "imgToAnns = defaultdict(list)\n",
    "for ann in total_data['annotations']:\n",
    "    anns[ann['id']] = ann\n",
    "    imgToAnns[ann['image_id']].append(ann)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d78e8172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of annotations:  120119\n",
      "number of images:  23694\n"
     ]
    }
   ],
   "source": [
    "print('number of annotations: ', len(anns))\n",
    "print('number of images: ', len(total_data['images']))\n",
    "# print(imgId_to_img[2021].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b932856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # carpart_inference_results: a list of dictionaries: save inference results of carpart model on images \n",
    "# def inference_result(model, image):\n",
    "    \n",
    "#     result = inference_detector(model,image.copy())\n",
    "#     out_image,pred_boxes,pred_segms,pred_labels,pred_scores = show_result_pyplot(model,image.copy(),result,score_thr=0.7)\n",
    "\n",
    "#     carpart_inference_result = {}\n",
    "#     carpart_inference_result[img_id] = {}\n",
    "#     carpart_inference_result[img_id]['labels'] = pred_labels.tolist()\n",
    "#     carpart_inference_result[img_id]['bboxes'] = (np.array(pred_boxes).astype(np.uint8)).tolist()\n",
    "#     carpart_inference_result[img_id]['scores'] = pred_scores.tolist()\n",
    "    \n",
    "#     segs = []\n",
    "#     for seg in pred_segms:\n",
    "#         contours, hierarchy = cv2.findContours(np.array(seg).astype(np.uint8),cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "#         for contour in contours:\n",
    "#             contour = contour.tolist()\n",
    "#             segs.append(contour)\n",
    "#     carpart_inference_result[img_id]['segmentations'] = segs\n",
    "    \n",
    "#     return carpart_inference_result\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a112043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe6dbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████████████████▋                                                                                                                 | 3191/23694 [24:42<58:23,  5.85it/s]"
     ]
    }
   ],
   "source": [
    "# carpart_inference_results = {}\n",
    "# file_name = 'carpart_inference_results'\n",
    "# json_path='../data/coco_datasets/datasets/scratch/annotations/'\n",
    "# inference_results_path = os.path.join(json_path, file_name+'.json')\n",
    "\n",
    "# with open(inference_results_path, 'w', encoding='utf-8') as json_file:\n",
    "#     json.dump(carpart_inference_results, json_file)\n",
    "\n",
    "\n",
    "# for img in tqdm(total_data['images']):\n",
    "#     img_name = img['file_name']\n",
    "#     img_id = img['id']\n",
    "#     image = cv2.imread(os.path.join(imgs_folder, img_name))\n",
    "    \n",
    "#     carpart_inference_results.update(inference_result(carpart_model, image))\n",
    "\n",
    "# with open(inference_results_path, mode='w', encoding='utf-8') as json_file:\n",
    "#         json.dump(inference_results_path, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50c9f22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#load inference results\n",
    "inference_results_path = '../data/coco_datasets/datasets/scratch/annotations/carpart_inference_results.json'\n",
    "\n",
    "with open(inference_results_path, \"r\") as read_file:\n",
    "    carpart_inference_results = json.load(read_file)\n",
    "print(len(carpart_inference_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3875c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result0 = carpart_inference_results[0]\n",
    "# print(result0)\n",
    "# print(type(result0['bboxes']), result0['bboxes'].shape)\n",
    "# print(type(result0['segmentations']), result0['segmentations'].shape)\n",
    "# print(type(result0['labels']), result0['labels'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f982f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate through all images in image folder to get a dict of iou(imgId: iuos), ...\n",
    "\n",
    "for img in tqdm(total_data['images']):\n",
    "    img_id = img['id']\n",
    "    img_name = img['file_name']\n",
    "    image = cv2.imread(os.path.join(imgs_folder, img_name))\n",
    "    anns = imgToAnns[img_id]\n",
    "    \n",
    "    #take predicted results of current img_id\n",
    "    inference_results = carpart_inference_results[img_id]\n",
    "    pred_boxes = inference_results['bboxes']\n",
    "    pre_segms = inference_results['segmentations']\n",
    "    pre_labels = inference_results['labels']\n",
    "    \n",
    "    if len(pred_segms) == 0:\n",
    "        continue\n",
    "    img_shape = pred_segms[0].shape\n",
    "    \n",
    "    #generate ground truth binary masks & compute iou\n",
    "    for i in range(len(pred_labels)):\n",
    "#         print('CARPART: {}'.format(classes[pred_labels[i]]), end = '  ')\n",
    "        for j in range(len(anns)):\n",
    "            ann = anns[j]\n",
    "            ground_truth_seg = ann['segmentation'][0]\n",
    "            \n",
    "            damage_size = define_damage_size(ground_truth_seg,img_shape)\n",
    "                \n",
    "            ground_truth_mask = draw_binary_mask(ground_truth_seg, img_shape)\n",
    "\n",
    "            predict_mask = draw_binary_mask(pred_segms[i], img_shape)  \n",
    "            \n",
    "            current_iou = iou(ground_truth_mask, predict_mask)\n",
    "#             iou['img_id'].append(current_iou)\n",
    "            if current_iou > 0:\n",
    "                if damage_size == 'Small': small_scratch[classes[pred_labels[i]]] += 1\n",
    "                elif damage_size == 'Medium': medium_scratch[classes[pred_labels[i]]] += 1\n",
    "                else: large_scratch[classes[pred_labels[i]]] += 1\n",
    "                \n",
    "                scratches_on_carparts[classes[pred_labels[i]]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81463776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc9fcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dataframe\n",
    "scratch_size = pd.DataFrame({'Carpart':small_scratch.keys(), 'Small damage':small_scratch.values(),\n",
    "                             'Medium damage':medium_scratch.values(), 'Large damage':large_scratch.values()})\n",
    "scratch_size.to_csv('statistical_charts/OLD_damaged_carpart_report.csv', index=False)\n",
    "scratch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58770bc2",
   "metadata": {},
   "source": [
    "### Plot bar charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f509d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot number of scratches on each carparts\n",
    "carparts = list(scratches_on_carparts.keys())\n",
    "scratches = list(scratches_on_carparts.values())\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.barh(carparts,scratches)\n",
    "\n",
    "plt.xlabel('number of scratches')\n",
    "plt.ylabel('type of carparts')\n",
    "plt.title('Scratches on carparts')\n",
    "plt.savefig('statistical_charts/OLD_no_scratches.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539a3389",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot number of large scratches on\n",
    "carparts = list(large_scratch.keys())\n",
    "no_large_scratch = list(large_scratch.values())\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.barh(carparts,no_large_scratch)\n",
    "\n",
    "plt.xlabel('number of large scratches')\n",
    "plt.ylabel('type of carparts')\n",
    "plt.title('Large scratches on carparts')\n",
    "plt.savefig('statistical_charts/OLD_no_large_scratches.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8ff306",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot number of medium scratches on\n",
    "carparts = list(medium_scratch.keys())\n",
    "no_medium_scratch = list(medium_scratch.values())\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.barh(carparts,no_medium_scratch)\n",
    "\n",
    "plt.xlabel('number of medium scratches')\n",
    "plt.ylabel('type of carparts')\n",
    "plt.title('Medium scratches on carparts')\n",
    "plt.savefig('statistical_charts/OLD_no_medium_scratches.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2c509a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot number of small scratches on\n",
    "\n",
    "carparts = list(small_scratch.keys())\n",
    "no_small_scratch = list(small_scratch.values())\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.barh(carparts,no_small_scratch)\n",
    "\n",
    "plt.xlabel('number of small scratches')\n",
    "plt.ylabel('type of carparts')\n",
    "plt.title('Small scratches on carparts')\n",
    "plt.savefig('statistical_charts/OLD_no_small_scratches.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a65170",
   "metadata": {},
   "source": [
    "# Merimen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577127f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merimen_imgs_folder = '../data/coco_datasets/datasets/merimen_coco/19_02_2022/scratch/images/'\n",
    "print(len([entry for entry in os.listdir(merimen_imgs_folder) if os.path.isfile(os.path.join(merimen_imgs_folder, entry))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85db9188",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load file total.json\n",
    "merimen_json_path='../data/coco_datasets/datasets/merimen_coco/19_02_2022/scratch/annotations/total.json'\n",
    "# with open(os.path.join(json_path, file_name+'.json'), 'w') as json_file:\n",
    "#     json.dump(total_data, json_file, indent=4)\n",
    "merimen_total_data = json.load(open(merimen_json_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23b565bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imgToAnns dict: mapping an image Id to a list of annotations\n",
    "anns = {}\n",
    "imgToAnns = defaultdict(list)\n",
    "for ann in merimen_total_data['annotations']:\n",
    "    anns[ann['id']] = ann\n",
    "    imgToAnns[ann['image_id']].append(ann)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8aa652d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of annotations:  120119\n",
      "number of images:  23694\n"
     ]
    }
   ],
   "source": [
    "print('number of annotations: ', len(anns))\n",
    "print('number of images: ', len(merimen_total_data['images']))\n",
    "# print(imgId_to_img[2021].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6d77fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "merimen_carpart_inference_results = []\n",
    "merimen_file_name = 'merimen_carpart_inference_results'\n",
    "merimen_json_path='../data/coco_datasets/datasets/merimen_coco/19_02_2022/scratch/annotations/'\n",
    "inference_results_path = os.path.join(merimen_json_path, merimen_file_name+'.json')\n",
    "\n",
    "with open(inference_results_path, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(merimen_carpart_inference_results, json_file)\n",
    "\n",
    "\n",
    "for img in merimen_total_data['images']:\n",
    "    img_name = img['file_name']\n",
    "    image = cv2.imread(os.path.join(merimen_imgs_folder, img_name))\n",
    "    \n",
    "    with open(inference_results_path, \"w\",encoding='utf-8') as json_file:\n",
    "        merimen_carpart_inference_results.append(inference_result(carpart_model, image))\n",
    "        json.dump(merimen_carpart_inference_results, json_file)\n",
    "print(len(merimen_carpart_inference_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de297a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load inference results\n",
    "inference_results_path = '../data/coco_datasets/datasets/merimen_coco/19_02_2022/scratch/annotations/merimen_carpart_inference_results.json'\n",
    "\n",
    "with open(inference_results_path, \"r\") as read_file:\n",
    "    merimen_carpart_inference_results = json.load(read_file)\n",
    "print(len(merimen_carpart_inference_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dba00e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result0 = merimen_carpart_inference_results[0]\n",
    "print(result0)\n",
    "print(type(result0['bboxes']), result0['bboxes'].shape)\n",
    "print(type(result0['segmentations']), result0['segmentations'].shape)\n",
    "print(type(result0['labels']), result0['labels'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d0c260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iou_dict = defaultdict(list)\n",
    "merimen_scratches_on_carparts = defaultdict(int)\n",
    "merimen_small_scratch = defaultdict(int)\n",
    "merimen_medium_scratch = defaultdict(int)\n",
    "merimen_large_scratch = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b57a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate through all images in image folder to get a dict of iou(imgId: iuos), \n",
    "for i, (img_id, anns) in enumerate(imgToAnns.items()):\n",
    "    print('imageid: {}'.format(img_id))\n",
    "    \n",
    "    #load image\n",
    "    for img in merimen_total_data['images']:\n",
    "        if img['id'] == img_id:\n",
    "            img_name = img['file_name']\n",
    "            image = cv2.imread(os.path.join(imgs_folder, img_name))\n",
    "            break \n",
    "    \n",
    "    #take predicted results\n",
    "    inference_results = merimen_carpart_inference_results[i]\n",
    "    pred_boxes = inference_results['bboxes']\n",
    "    pre_segms = inference_results['segmentations']\n",
    "    pre_labels = inference_results['labels']\n",
    "    \n",
    "    if len(pred_segms) == 0:\n",
    "        continue\n",
    "    img_shape = pred_segms[0].shape\n",
    "    \n",
    "    #generate ground truth binary masks & compute iou\n",
    "    for i in range(len(pred_labels)):\n",
    "#         print('CARPART: {}'.format(classes[pred_labels[i]]), end = '  ')\n",
    "        for j in range(len(anns)):\n",
    "            ann = anns[j]\n",
    "            ground_truth_seg = ann['segmentation'][0]\n",
    "            \n",
    "            damage_size = define_damage_size(ground_truth_seg,img_shape)\n",
    "                \n",
    "            ground_truth_mask = draw_binary_mask(ground_truth_seg, img_shape)\n",
    "\n",
    "            predict_mask = draw_binary_mask(pred_segms[i], img_shape)  \n",
    "            \n",
    "            current_iou = iou(ground_truth_mask, predict_mask)\n",
    "#             iou['img_id'].append(current_iou)\n",
    "            if current_iou > 0:\n",
    "                if damage_size == 'Small': merimen_small_scratch[classes[pred_labels[i]]] += 1\n",
    "                elif damage_size == 'Medium': merimen_medium_scratch[classes[pred_labels[i]]] += 1\n",
    "                else: merimen_large_scratch[classes[pred_labels[i]]] += 1\n",
    "                \n",
    "                merimen_scratches_on_carparts[classes[pred_labels[i]]] += 1\n",
    "#         print(scratches_on_carparts[classes[pred_labels[i]]])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675d5ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2e2c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dataframe\n",
    "merimen_scratch_size = pd.DataFrame({'Carpart':merimen_small_scratch.keys(), 'Small damage':merimen_small_scratch.values(),\n",
    "                             'Medium damage':merimen_medium_scratch.values(), 'Large damage':merimen_large_scratch.values()})\n",
    "merimen_scratch_size.to_csv('statistical_charts/MERIMEN_damaged_carpart_report.csv', index=False)\n",
    "merimen_scratch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36041b94",
   "metadata": {},
   "source": [
    "### Plot bar charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9dae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot number of scratches on each carparts\n",
    "carparts = list(merimen_scratches_on_carparts.keys())\n",
    "scratches = list(merimen_scratches_on_carparts.values())\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.barh(carparts,scratches)\n",
    "\n",
    "plt.xlabel('number of scratches')\n",
    "plt.ylabel('type of carparts')\n",
    "plt.title('Scratches on carparts')\n",
    "plt.savefig('statistical_charts/merimen_no_scratches.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904ef7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot number of large scratches on\n",
    "carparts = list(merimen_large_scratch.keys())\n",
    "no_large_scratch = list(merimen_large_scratch.values())\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.barh(carparts,no_large_scratch)\n",
    "\n",
    "plt.xlabel('number of large scratches')\n",
    "plt.ylabel('type of carparts')\n",
    "plt.title('Large scratches on carparts')\n",
    "plt.savefig('statistical_charts/merimen_no_large_scratches.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21552cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot number of medium scratches on\n",
    "carparts = list(merimen_medium_scratch.keys())\n",
    "no_medium_scratch = list(merimen_medium_scratch.values())\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.barh(carparts,no_medium_scratch)\n",
    "\n",
    "plt.xlabel('number of medium scratches')\n",
    "plt.ylabel('type of carparts')\n",
    "plt.title('Medium scratches on carparts')\n",
    "plt.savefig('statistical_charts/merimen_no_medium_scratches.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954751d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot number of small scratches on\n",
    "\n",
    "carparts = list(merimen_small_scratch.keys())\n",
    "no_small_scratch = list(merimen_small_scratch.values())\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.barh(carparts,no_small_scratch)\n",
    "\n",
    "plt.xlabel('number of small scratches')\n",
    "plt.ylabel('type of carparts')\n",
    "plt.title('Small scratches on carparts')\n",
    "plt.savefig('statistical_charts/merimen_no_small_scratches.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038849fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d4189f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a946d2d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b472005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf9cc5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a7d020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25d907a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e45a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e5e537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ebbcba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d39e636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb6a7cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd6e31d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02564b87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dce85a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37293b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3935d5d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29919c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2c7c06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
