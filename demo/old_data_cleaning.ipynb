{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "798751e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import json\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffc0774a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/mmdetection/data/coco_datasets/datasets/scratch/annotations/'\n",
    "train_data_path = '/mmdetection/data/coco_datasets/datasets/scratch/annotations/train.json'\n",
    "valid_data_path = '/mmdetection/data/coco_datasets/datasets/scratch/annotations/valid.json'\n",
    "test_data_path = '/mmdetection/data/coco_datasets/datasets/scratch/annotations/test.json'\n",
    "\n",
    "train_data = json.load(open(train_data_path))\n",
    "valid_data = json.load(open(valid_data_path))\n",
    "test_data = json.load(open(test_data_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbd1b37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_area(seg):\n",
    "    seg = np.array(seg).reshape(-1,2).astype(np.int32)\n",
    "    area = cv2.contourArea(seg)\n",
    "    if area == 0:\n",
    "        area = 1e-5\n",
    "    return area\n",
    "\n",
    "def double_check(data):\n",
    "    img_ids = [img['id'] for img in data['images']]\n",
    "    img_ids_in_annos = set([ann['image_id'] for ann in data['annotations']])\n",
    "    differential_quant = len(img_ids) - len(img_ids_in_annos)\n",
    "    if (differential_quant <= 0):\n",
    "        print(\"check 'double_check' function again\")\n",
    "    else:\n",
    "        print('have positive differential quantity')\n",
    "        new_images = []\n",
    "        for img in data['images']:\n",
    "            if img['id'] in img_ids_in_annos:\n",
    "                new_images.append(img)\n",
    "        data['images'] = new_images\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2e704d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data, name=None):\n",
    "    seg_area = {}\n",
    "    seg_img_ratio = {}\n",
    "    img_id = {}\n",
    "    for ann in data['annotations']:\n",
    "        seg_area[ann['id']] = compute_area(ann['segmentation'])\n",
    "        img_id[ann['id']] = ann['image_id']\n",
    "        \n",
    "        for img in data['images']:\n",
    "            if ann['image_id'] == img['id']:\n",
    "                img_area = img['width'] * img['height']\n",
    "                break\n",
    "        seg_img_ratio[ann['id']] = seg_area[ann['id']]/img_area\n",
    "    \n",
    "    df_name =  name+'_df'\n",
    "    df = pd.DataFrame({'anno_id': seg_area.keys(),\n",
    "                      'img_id': img_id.values(),\n",
    "                      'seg_area': seg_area.values(),\n",
    "                      'seg_img_ratio': seg_img_ratio.values()}) \n",
    "    df.to_csv('statistical_charts/old_{}.csv'.format(df_name),index=False)\n",
    "    \n",
    "    upper_limit = 0.15\n",
    "    lower_limit = np.exp(-11)\n",
    "    under_lower_outlier = under_lower_ratio_outlier = df[(df.seg_img_ratio<=lower_limit)]\n",
    "    above_upper_ratio_outlier = df[(df.seg_img_ratio>=upper_limit)]\n",
    "    \n",
    "    removed_ann_id = list(under_lower_ratio_outlier.anno_id)\n",
    "    removed_img_id = list(set(above_upper_ratio_outlier.img_id))\n",
    "\n",
    "    print('no removed ann id: ',len(removed_ann_id), \n",
    "          'no removed img id: ', len(removed_img_id))\n",
    "    \n",
    "    \n",
    "    print('original ann id: ',len(data['images']), \n",
    "          'original img id: ',len(data['annotations']))\n",
    "    new_json = copy.deepcopy(data)\n",
    "\n",
    "    for ann in new_json['annotations']:\n",
    "        if ann['image_id'] in removed_img_id:\n",
    "            removed_ann_id.append(ann['id'])\n",
    "\n",
    "    new_json['images'] = [img for img in new_json['images'] if img['id'] not in removed_img_id]\n",
    "    new_json['annotations'] = [ann for ann in new_json['annotations'] if ann['id'] not in removed_ann_id]\n",
    "    print(len(new_json['images']), len(new_json['annotations']))\n",
    "    new_json = double_check(new_json)\n",
    "    \n",
    "    new_json_name = 'clean_'+name+'.json'\n",
    "    \n",
    "    path = os.path.join(data_dir, new_json_name)\n",
    "    with open(path, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(new_json, json_file, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1dd08495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no removed ann id:  3364 no removed img id:  154\n",
      "original ann id:  16144 original img id:  81642\n",
      "15990 77763\n",
      "have positive differential quantity\n"
     ]
    }
   ],
   "source": [
    "clean_data(train_data, name='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2982426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no removed ann id:  752 no removed img id:  32\n",
      "original ann id:  3775 original img id:  19024\n",
      "3743 18164\n",
      "have positive differential quantity\n"
     ]
    }
   ],
   "source": [
    "clean_data(valid_data, name='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94810e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no removed ann id:  973 no removed img id:  35\n",
      "original ann id:  3775 original img id:  19453\n",
      "3740 18358\n",
      "have positive differential quantity\n"
     ]
    }
   ],
   "source": [
    "clean_data(test_data, name='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ecfafcea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5089"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3364+752+973"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96530cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "154+32+35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9cb2b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcaee50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
